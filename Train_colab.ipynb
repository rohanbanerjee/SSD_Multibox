{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Train_colab.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "AIOLFHCMP95h",
        "colab_type": "code",
        "outputId": "3ebe14e3-708f-4e34-8035-dd2e9474d2f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "s8Ei8O8JQasT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b5aL7vrLQ336",
        "colab_type": "code",
        "outputId": "40ad5788-c299-4d1d-c608-71cad196456b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "cd images\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PFb53-N0VRCZ",
        "colab_type": "code",
        "outputId": "4ec8e31f-9c93-458c-9abb-ce3bad5be9d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Part11.jpg  Part22.jpg\tPart31.jpg  Part34.jpg\tPart37.jpg\n",
            "Part12.jpg  Part23.jpg\tPart32.jpg  Part35.jpg\tPart38.jpg\n",
            "Part18.jpg  Part24.jpg\tPart33.jpg  Part36.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MoUwv8BAVkjC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4R9R9DkWV0N9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!rmdir dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8K7N5ARiWVPk",
        "colab_type": "code",
        "outputId": "4ad83ad6-75b7-4a33-b7db-7756f9e5a95d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "cd ..\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dmWKRXXwWXxU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n5sUpblqWbaY",
        "colab_type": "code",
        "outputId": "c313b10e-66b4-4996-816b-249118a65303",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/pierluigiferrari/ssd_keras.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ssd_keras'...\n",
            "remote: Enumerating objects: 1608, done.\u001b[K\n",
            "remote: Total 1608 (delta 0), reused 0 (delta 0), pack-reused 1608\u001b[K\n",
            "Receiving objects: 100% (1608/1608), 19.70 MiB | 7.69 MiB/s, done.\n",
            "Resolving deltas: 100% (1057/1057), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eY5noXEVa3PU",
        "colab_type": "code",
        "outputId": "1996bb79-21ab-4c54-ebf3-f341503fb146",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install keras==2.2.2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras==2.2.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/34/7d/b1dedde8af99bd82f20ed7e9697aac0597de3049b1f786aa2aac3b9bd4da/Keras-2.2.2-py2.py3-none-any.whl (299kB)\n",
            "\u001b[K    100% |████████████████████████████████| 307kB 24.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.2) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.2) (1.14.6)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.2) (3.13)\n",
            "Collecting keras-preprocessing==1.0.2 (from keras==2.2.2)\n",
            "  Downloading https://files.pythonhosted.org/packages/71/26/1e778ebd737032749824d5cba7dbd3b0cf9234b87ab5ec79f5f0403ca7e9/Keras_Preprocessing-1.0.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.2) (1.11.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.2.2) (2.8.0)\n",
            "Collecting keras-applications==1.0.4 (from keras==2.2.2)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/90/8f327deaa37a71caddb59b7b4aaa9d4b3e90c0e76f8c2d1572005278ddc5/Keras_Applications-1.0.4-py2.py3-none-any.whl (43kB)\n",
            "\u001b[K    100% |████████████████████████████████| 51kB 16.5MB/s \n",
            "\u001b[31mtensorflow 1.12.0 has requirement keras-applications>=1.0.6, but you'll have keras-applications 1.0.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mtensorflow 1.12.0 has requirement keras-preprocessing>=1.0.5, but you'll have keras-preprocessing 1.0.2 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: keras-preprocessing, keras-applications, keras\n",
            "  Found existing installation: Keras-Preprocessing 1.0.5\n",
            "    Uninstalling Keras-Preprocessing-1.0.5:\n",
            "      Successfully uninstalled Keras-Preprocessing-1.0.5\n",
            "  Found existing installation: Keras-Applications 1.0.6\n",
            "    Uninstalling Keras-Applications-1.0.6:\n",
            "      Successfully uninstalled Keras-Applications-1.0.6\n",
            "  Found existing installation: Keras 2.2.4\n",
            "    Uninstalling Keras-2.2.4:\n",
            "      Successfully uninstalled Keras-2.2.4\n",
            "Successfully installed keras-2.2.2 keras-applications-1.0.4 keras-preprocessing-1.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6BAP5BKgbBSE",
        "colab_type": "code",
        "outputId": "f2e07d37-4516-42aa-af73-54fa7c729f07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==1.10.0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.10.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ee/e6/a6d371306c23c2b01cd2cb38909673d17ddd388d9e4b3c0f6602bfd972c8/tensorflow-1.10.0-cp36-cp36m-manylinux1_x86_64.whl (58.4MB)\n",
            "\u001b[K    100% |████████████████████████████████| 58.4MB 615kB/s \n",
            "\u001b[?25hCollecting numpy<=1.14.5,>=1.13.3 (from tensorflow==1.10.0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/68/1e/116ad560de97694e2d0c1843a7a0075cc9f49e922454d32f49a80eb6f1f2/numpy-1.14.5-cp36-cp36m-manylinux1_x86_64.whl (12.2MB)\n",
            "\u001b[K    100% |████████████████████████████████| 12.2MB 4.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10.0) (3.6.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10.0) (0.32.3)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10.0) (1.11.0)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10.0) (0.6.1)\n",
            "Collecting setuptools<=39.1.0 (from tensorflow==1.10.0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8c/10/79282747f9169f21c053c562a0baa21815a8c7879be97abd930dbcf862e8/setuptools-39.1.0-py2.py3-none-any.whl (566kB)\n",
            "\u001b[K    100% |████████████████████████████████| 573kB 18.3MB/s \n",
            "\u001b[?25hCollecting tensorboard<1.11.0,>=1.10.0 (from tensorflow==1.10.0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c6/17/ecd918a004f297955c30b4fffbea100b1606c225dbf0443264012773c3ff/tensorboard-1.10.0-py3-none-any.whl (3.3MB)\n",
            "\u001b[K    100% |████████████████████████████████| 3.3MB 7.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10.0) (1.15.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10.0) (0.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10.0) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10.0) (0.7.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.11.0,>=1.10.0->tensorflow==1.10.0) (3.0.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.11.0,>=1.10.0->tensorflow==1.10.0) (0.14.1)\n",
            "\u001b[31mspacy 2.0.18 has requirement numpy>=1.15.0, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mmagenta 0.3.19 has requirement tensorflow>=1.12.0, but you'll have tensorflow 1.10.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mfeaturetools 0.4.1 has requirement pandas>=0.23.0, but you'll have pandas 0.22.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mcufflinks 0.14.6 has requirement plotly>=3.0.0, but you'll have plotly 1.12.12 which is incompatible.\u001b[0m\n",
            "Installing collected packages: numpy, setuptools, tensorboard, tensorflow\n",
            "  Found existing installation: numpy 1.14.6\n",
            "    Uninstalling numpy-1.14.6:\n",
            "      Successfully uninstalled numpy-1.14.6\n",
            "  Found existing installation: setuptools 40.6.3\n",
            "    Uninstalling setuptools-40.6.3:\n",
            "      Successfully uninstalled setuptools-40.6.3\n",
            "  Found existing installation: tensorboard 1.12.1\n",
            "    Uninstalling tensorboard-1.12.1:\n",
            "      Successfully uninstalled tensorboard-1.12.1\n",
            "  Found existing installation: tensorflow 1.12.0\n",
            "    Uninstalling tensorflow-1.12.0:\n",
            "      Successfully uninstalled tensorflow-1.12.0\n",
            "Successfully installed numpy-1.14.5 setuptools-39.1.0 tensorboard-1.10.0 tensorflow-1.10.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bsakQlUpbKHU",
        "colab_type": "code",
        "outputId": "73696b74-1def-4271-f3e0-468a7298c6dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.14.5"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy==1.14.5 in /usr/local/lib/python3.6/dist-packages (1.14.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NGhzFD42bi2_",
        "colab_type": "code",
        "outputId": "ae99c85b-1afb-44a9-b00d-154b033932de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install matplotlib==3.0.2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting matplotlib==3.0.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/07/16d781df15be30df4acfd536c479268f1208b2dfbc91e9ca5d92c9caf673/matplotlib-3.0.2-cp36-cp36m-manylinux1_x86_64.whl (12.9MB)\n",
            "\u001b[K    100% |████████████████████████████████| 12.9MB 3.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.0.2) (1.14.5)\n",
            "Collecting kiwisolver>=1.0.1 (from matplotlib==3.0.2)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/a7/88719d132b18300b4369fbffa741841cfd36d1e637e1990f27929945b538/kiwisolver-1.0.1-cp36-cp36m-manylinux1_x86_64.whl (949kB)\n",
            "\u001b[K    100% |████████████████████████████████| 952kB 20.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.0.2) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.0.2) (2.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.0.2) (2.5.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib==3.0.2) (39.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib==3.0.2) (1.11.0)\n",
            "\u001b[31myellowbrick 0.9 has requirement matplotlib<3.0,>=1.5.1, but you'll have matplotlib 3.0.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mmagenta 0.3.19 has requirement tensorflow>=1.12.0, but you'll have tensorflow 1.10.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: kiwisolver, matplotlib\n",
            "  Found existing installation: matplotlib 2.1.2\n",
            "    Uninstalling matplotlib-2.1.2:\n",
            "      Successfully uninstalled matplotlib-2.1.2\n",
            "Successfully installed kiwisolver-1.0.1 matplotlib-3.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9uhHtm6Lbod3",
        "colab_type": "code",
        "outputId": "7e63a884-d6c9-4b23-b24f-dbf0b4911bc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install opencv-python==3.4.2.16"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting opencv-python==3.4.2.16\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fa/7d/5042b668a8ed41d2a80b8c172f5efcd572e3c046c75ae029407e19b7fc68/opencv_python-3.4.2.16-cp36-cp36m-manylinux1_x86_64.whl (25.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 25.0MB 1.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python==3.4.2.16) (1.14.5)\n",
            "Installing collected packages: opencv-python\n",
            "  Found existing installation: opencv-python 3.4.4.19\n",
            "    Uninstalling opencv-python-3.4.4.19:\n",
            "      Successfully uninstalled opencv-python-3.4.4.19\n",
            "Successfully installed opencv-python-3.4.2.16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GRpbHf85b8Bn",
        "colab_type": "code",
        "outputId": "5d6966f8-8f1e-44e2-b4ce-d57498bbce62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "cd ssd_keras"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/ssd_keras\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lm1R1JC3b_WE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "\n",
        "from keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger, TerminateOnNaN\n",
        "import keras as K\n",
        "from keras.models import load_model\n",
        "from math import ceil\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras import metrics\n",
        "\n",
        "\n",
        "from models.keras_ssd7 import build_model\n",
        "from keras_loss_function.keras_ssd_loss import SSDLoss\n",
        "from keras_layers.keras_layer_AnchorBoxes import AnchorBoxes\n",
        "from keras_layers.keras_layer_DecodeDetections import DecodeDetections\n",
        "from keras_layers.keras_layer_DecodeDetectionsFast import DecodeDetectionsFast\n",
        "\n",
        "from ssd_encoder_decoder.ssd_input_encoder import SSDInputEncoder\n",
        "from ssd_encoder_decoder.ssd_output_decoder import decode_detections, decode_detections_fast\n",
        "\n",
        "from data_generator.object_detection_2d_data_generator import DataGenerator\n",
        "from data_generator.object_detection_2d_misc_utils import apply_inverse_transforms\n",
        "from data_generator.data_augmentation_chain_variable_input_size import DataAugmentationVariableInputSize\n",
        "from data_generator.data_augmentation_chain_constant_input_size import DataAugmentationConstantInputSize\n",
        "from data_generator.data_augmentation_chain_original_ssd import SSDDataAugmentation\n",
        "\n",
        "config = tf.ConfigProto( device_count = {'GPU': 0 , 'CPU': 56} )\n",
        "sess = tf.Session(config=config) \n",
        "K.backend.set_session(sess)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KGML26_OcB_n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "img_height = 698 # Height of the input images\n",
        "img_width = 698 # Width of the input images\n",
        "img_channels = 3 # Number of color channels of the input images\n",
        "intensity_mean = 127.5 # Set this to your preference (maybe `None`). The current settings transform the input pixel values to the interval `[-1,1]`.\n",
        "intensity_range = 127.5 # Set this to your preference (maybe `None`). The current settings transform the input pixel values to the interval `[-1,1]`.\n",
        "n_classes = 2 # Number of positive classes\n",
        "scales = [0.08, 0.16, 0.32, 0.64, 0.96] # An explicit list of anchor box scaling factors. If this is passed, it will override `min_scale` and `max_scale`.\n",
        "aspect_ratios = [0.5, 1.0, 2.0] # The list of aspect ratios for the anchor boxes\n",
        "two_boxes_for_ar1 = True # Whether or not you want to generate two anchor boxes for aspect ratio 1\n",
        "steps = None # In case you'd like to set the step sizes for the anchor box grids manually; not recommended\n",
        "offsets = None # In case you'd like to set the offsets for the anchor box grids manually; not recommended\n",
        "clip_boxes = False # Whether or not to clip the anchor boxes to lie entirely within the image boundaries\n",
        "variances = [1.0, 1.0, 1.0, 1.0] # The list of variances by which the encoded target coordinates are scaled\n",
        "normalize_coords = True # Whether or not the model is supposed to use coordinates relative to the image size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qpnCfDPPcHVW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = build_model(image_size=(img_height, img_width, img_channels),\n",
        "                    n_classes=n_classes,\n",
        "                    mode='training',\n",
        "                    l2_regularization=0.0005,\n",
        "                    scales=scales,\n",
        "                    aspect_ratios_global=aspect_ratios,\n",
        "                    aspect_ratios_per_layer=None,\n",
        "                    two_boxes_for_ar1=two_boxes_for_ar1,\n",
        "                    steps=steps,\n",
        "                    offsets=offsets,\n",
        "                    clip_boxes=clip_boxes,\n",
        "                    variances=variances,\n",
        "                    normalize_coords=normalize_coords,\n",
        "                    subtract_mean=intensity_mean,\n",
        "                    divide_by_stddev=intensity_range)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1M11bRy6cLbT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
        "\n",
        "ssd_loss = SSDLoss(neg_pos_ratio=3, alpha=1.0)\n",
        "\n",
        "model.compile(optimizer=adam, loss=ssd_loss.compute_loss, metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gdj67Km7cauk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_dataset = DataGenerator(load_images_into_memory=False, hdf5_dataset_path=None)\n",
        "val_dataset = DataGenerator(load_images_into_memory=False, hdf5_dataset_path=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6oG04hthceaz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "images_dir = '/content/images/'\n",
        "\n",
        "# Ground truth\n",
        "train_labels_filename = '/content/dataset/train.csv'\n",
        "val_labels_filename   = '/content/dataset/test.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j5KWA_Rjcqu2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_dataset.parse_csv(images_dir=images_dir,\n",
        "                        labels_filename=train_labels_filename,\n",
        "                        input_format=['image_name', 'xmin', 'ymin', 'xmax', 'ymax', 'class_id'], # This is the order of the first six columns in the CSV file that contains the labels for your dataset. If your labels are in XML format, maybe the XML parser will be helpful, check the documentation.\n",
        "                        include_classes='all')\n",
        "\n",
        "val_dataset.parse_csv(images_dir=images_dir,\n",
        "                      labels_filename=val_labels_filename,\n",
        "                      input_format=['image_name', 'xmin', 'ymin', 'xmax', 'ymax', 'class_id'],\n",
        "                      include_classes='all')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Tli5Ta7hcydk",
        "colab_type": "code",
        "outputId": "dda85813-11c0-41a1-9f14-e1ec7237d8b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "train_dataset.create_hdf5_dataset(file_path='train.h5',\n",
        "                                  resize=False,\n",
        "                                  variable_image_size=True,\n",
        "                                  verbose=True)\n",
        "\n",
        "val_dataset.create_hdf5_dataset(file_path='test.h5',\n",
        "                                resize=False,\n",
        "                                variable_image_size=True,\n",
        "                                verbose=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating HDF5 dataset: 100%|██████████| 10/10 [00:00<00:00, 51.90it/s]\n",
            "Creating HDF5 dataset: 100%|██████████| 5/5 [00:00<00:00, 57.39it/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ILEDqjP4c3Y6",
        "colab_type": "code",
        "outputId": "cb1169c8-0f04-4531-8895-d0ed67a107ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "train_dataset_size = train_dataset.get_dataset_size()\n",
        "val_dataset_size   = val_dataset.get_dataset_size()\n",
        "\n",
        "print(\"Number of images in the training dataset:\\t{:>6}\".format(train_dataset_size))\n",
        "print(\"Number of images in the validation dataset:\\t{:>6}\".format(val_dataset_size))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of images in the training dataset:\t    10\n",
            "Number of images in the validation dataset:\t     5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "s_wH5xf1dEAu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 30\n",
        "\n",
        "# 4: Define the image processing chain.\n",
        "\n",
        "data_augmentation_chain = DataAugmentationConstantInputSize(random_brightness=(-48, 48, 0.5),\n",
        "                                                            random_contrast=(0.5, 1.8, 0.5),\n",
        "                                                            random_saturation=(0.5, 1.8, 0.5),\n",
        "                                                            random_hue=(18, 0.5),\n",
        "                                                            random_flip=0.5,\n",
        "                                                            random_translate=((0.03,0.5), (0.03,0.5), 0.5),\n",
        "                                                            random_scale=(0.5, 2.0, 0.5),\n",
        "                                                            n_trials_max=3,\n",
        "                                                            clip_boxes=True,\n",
        "                                                            overlap_criterion='area',\n",
        "                                                            bounds_box_filter=(0.3, 1.0),\n",
        "                                                            bounds_validator=(0.5, 1.0),\n",
        "                                                            n_boxes_min=1,\n",
        "                                                            background=(0,0,0))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5262JA5EdP7F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predictor_sizes = [model.get_layer('classes4').output_shape[1:3],\n",
        "                   model.get_layer('classes5').output_shape[1:3],\n",
        "                   model.get_layer('classes6').output_shape[1:3],\n",
        "                   model.get_layer('classes7').output_shape[1:3]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "24PR5XoudToz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ssd_input_encoder = SSDInputEncoder(img_height=img_height,\n",
        "                                    img_width=img_width,\n",
        "                                    n_classes=n_classes,\n",
        "                                    predictor_sizes=predictor_sizes,\n",
        "                                    scales=scales,\n",
        "                                    aspect_ratios_global=aspect_ratios,\n",
        "                                    two_boxes_for_ar1=two_boxes_for_ar1,\n",
        "                                    steps=steps,\n",
        "                                    offsets=offsets,\n",
        "                                    clip_boxes=clip_boxes,\n",
        "                                    variances=variances,\n",
        "                                    matching_type='multi',\n",
        "                                    pos_iou_threshold=0.5,\n",
        "                                    neg_iou_limit=0.3,\n",
        "                                    normalize_coords=normalize_coords)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kcuKzAE-dg5-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_generator = train_dataset.generate(batch_size=batch_size,\n",
        "                                         shuffle=True,\n",
        "                                         transformations=[data_augmentation_chain],\n",
        "                                         label_encoder=ssd_input_encoder,\n",
        "                                         returns={'processed_images',\n",
        "                                                  'encoded_labels'},\n",
        "                                         keep_images_without_gt=False)\n",
        "\n",
        "val_generator = val_dataset.generate(batch_size=batch_size,\n",
        "                                     shuffle=False,\n",
        "                                     transformations=[],\n",
        "                                     label_encoder=ssd_input_encoder,\n",
        "                                     returns={'processed_images',\n",
        "                                              'encoded_labels'},\n",
        "                                     keep_images_without_gt=False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HQvfBuxldnY0",
        "colab_type": "code",
        "outputId": "db04eac3-13d1-4ac4-9bc4-1b818d625f63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "model_checkpoint = ModelCheckpoint(filepath='ssd7_epoch-{epoch:02d}_loss-{loss:.4f}_val_loss-{val_loss:.4f}.h5',\n",
        "                                   monitor='val_acc',\n",
        "                                   verbose=1,\n",
        "                                   save_best_only=True,\n",
        "                                   save_weights_only=True,\n",
        "                                   mode='auto',\n",
        "                                   period=1)\n",
        "\n",
        "\n",
        "csv_logger = CSVLogger(filename='ssd7_training_log.csv',\n",
        "                       separator=',',\n",
        "                       append=True)\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss',\n",
        "                               min_delta=0.0,\n",
        "                               patience=10,\n",
        "                               verbose=1)\n",
        "\n",
        "reduce_learning_rate = ReduceLROnPlateau(monitor='val_loss',\n",
        "                                         factor=0.2,\n",
        "                                         patience=8,\n",
        "                                         verbose=1,\n",
        "                                         epsilon=0.001,\n",
        "                                         cooldown=0,\n",
        "                                         min_lr=0.00001)\n",
        "\n",
        "mc = K.callbacks.ModelCheckpoint('weights{epoch:08d}.h5', \n",
        "                                     save_weights_only=True, period=5)\n",
        "callbacks = [model_checkpoint,\n",
        "             csv_logger,\n",
        "             early_stopping,\n",
        "             reduce_learning_rate,\n",
        "            mc]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6Hz2fY48dtfE",
        "colab_type": "code",
        "outputId": "2980cc34-477e-4d11-e288-73cc234f95ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "cell_type": "code",
      "source": [
        "initial_epoch = 0\n",
        "final_epoch     = 20\n",
        "steps_per_epoch = 50\n",
        "\n",
        "# history = model.fit_generator(generator=train_generator,\n",
        "#                               steps_per_epoch=steps_per_epoch,\n",
        "#                               epochs=final_epoch,\n",
        "#                               callbacks=callbacks,\n",
        "#                               validation_data=val_generator,\n",
        "#                               validation_steps=ceil(val_dataset_size/batch_size),\n",
        "#                               initial_epoch=initial_epoch)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    history = model.fit_generator(generator=train_generator, \n",
        "                                  steps_per_epoch=steps_per_epoch,\n",
        "                                  epochs=final_epoch,\n",
        "                                  callbacks=callbacks,\n",
        "                                  validation_data=val_generator,\n",
        "                                  validation_steps=ceil(val_dataset_size/batch_size),\n",
        "                                  initial_epoch=initial_epoch)\n",
        "\n",
        "model.save('model_colab.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "50/50 [==============================] - 2371s 47s/step - loss: 0.2619 - acc: 0.0288 - val_loss: 0.1303 - val_acc: 0.0605\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.06051, saving model to ssd7_epoch-01_loss-0.2619_val_loss-0.1303.h5\n",
            "Epoch 2/20\n",
            "50/50 [==============================] - 2319s 46s/step - loss: 0.0763 - acc: 0.0462 - val_loss: 0.0392 - val_acc: 0.0605\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.06051 to 0.06053, saving model to ssd7_epoch-02_loss-0.0763_val_loss-0.0392.h5\n",
            "Epoch 3/20\n",
            "50/50 [==============================] - 2327s 47s/step - loss: 0.0239 - acc: 0.0467 - val_loss: 0.0132 - val_acc: 0.0605\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.06053\n",
            "Epoch 4/20\n",
            "44/50 [=========================>....] - ETA: 4:36 - loss: 0.0090 - acc: 0.0450"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "s1XCZvSGeaBI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,12))\n",
        "plt.plot(history.history['loss'], label='loss')\n",
        "plt.plot(history.history['val_loss'], label='val_loss')\n",
        "plt.legend(loc='upper right', prop={'size': 24});"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-J8EbQb7fha_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predict_generator = val_dataset.generate(batch_size=1,\n",
        "                                         shuffle=True,\n",
        "                                         transformations=[],\n",
        "                                         label_encoder=None,\n",
        "                                         returns={'processed_images',\n",
        "                                                  'processed_labels',\n",
        "                                                  'filenames'},\n",
        "                                         keep_images_without_gt=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Jx6yzp5Mfnlj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_images, batch_labels, batch_filenames = next(predict_generator)\n",
        "\n",
        "i = 0 # Which batch item to look at\n",
        "\n",
        "print(\"Image:\", batch_filenames[i])\n",
        "print()\n",
        "print(\"Ground truth boxes:\\n\")\n",
        "print(batch_labels[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hwQp1oKAfttY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(batch_images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FB2hRekRfxIK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_pred_decoded = decode_detections(y_pred,\n",
        "                                   confidence_thresh=0.5,\n",
        "                                   iou_threshold=0.45,\n",
        "                                   top_k=200,\n",
        "                                   normalize_coords=normalize_coords,\n",
        "                                   img_height=img_height,\n",
        "                                   img_width=img_width)\n",
        "\n",
        "np.set_printoptions(precision=2, suppress=True, linewidth=90)\n",
        "print(\"Predicted boxes:\\n\")\n",
        "print('   class   conf xmin   ymin   xmax   ymax')\n",
        "print(y_pred_decoded[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zs_kSLBdf07o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,12))\n",
        "plt.imshow(batch_images[i])\n",
        "\n",
        "current_axis = plt.gca()\n",
        "\n",
        "colors = plt.cm.hsv(np.linspace(0, 1, n_classes+1)).tolist() # Set the colors for the bounding boxes\n",
        "classes = ['background', 'car', 'truck', 'pedestrian', 'bicyclist', 'light'] # Just so we can print class names onto the image instead of IDs\n",
        "\n",
        "# Draw the ground truth boxes in green (omit the label for more clarity)\n",
        "for box in batch_labels[i]:\n",
        "    xmin = box[1]\n",
        "    ymin = box[2]\n",
        "    xmax = box[3]\n",
        "    ymax = box[4]\n",
        "    label = '{}'.format(classes[int(box[0])])\n",
        "    current_axis.add_patch(plt.Rectangle((xmin, ymin), xmax-xmin, ymax-ymin, color='green', fill=False, linewidth=2))  \n",
        "    #current_axis.text(xmin, ymin, label, size='x-large', color='white', bbox={'facecolor':'green', 'alpha':1.0})\n",
        "\n",
        "# Draw the predicted boxes in blue\n",
        "for box in y_pred_decoded[i]:\n",
        "    xmin = box[-4]\n",
        "    ymin = box[-3]\n",
        "    xmax = box[-2]\n",
        "    ymax = box[-1]\n",
        "    color = colors[int(box[0])]\n",
        "    label = '{}: {:.2f}'.format(classes[int(box[0])], box[1])\n",
        "    current_axis.add_patch(plt.Rectangle((xmin, ymin), xmax-xmin, ymax-ymin, color=color, fill=False, linewidth=2))  \n",
        "    current_axis.text(xmin, ymin, label, size='x-large', color='white', bbox={'facecolor':color, 'alpha':1.0})"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}